---
title: "p8105_hw3_yj2752"
author: "Yixuan Jiao"
output: github_document
---

```{r}
library(tidyverse)
library(patchwork)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

### Problem1
Load instacart dataset.
```{r}
data("instacart")
```
See ordered aisle.
```{r}
instacart %>%
  count(aisle) %>%
  arrange(desc(n))
```
Plot aisle with number of items.
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

Order number of products in each of the three aisles.
```{r}
instacart %>% 
  filter(aisle == "baking ingredients"|aisle == "dog food care"| aisle == "packaged vegetables fruits") %>% 
  group_by(aisle) %>%
  count(product_name) %>%
  mutate(rank = min_rank(desc(n))) %>%
  filter(rank < 4) %>%
  arrange(aisle,rank)
```
Show mean hour of order in each day of two products.
```{r}
instacart %>%
  filter(product_name=="Pink Lady Apples"|product_name =="Coffee Ice Cream") %>%
  group_by(product_name,order_dow) %>%
  summarise(mean_hod = mean(order_hour_of_day)) %>%
  rename('Day' = order_dow) %>%
  pivot_wider(names_from = Day,values_from = mean_hod)
  #spread(key = Day, value = mean_hod)
```


### Problem2
Firstly, load the dataset using `read_csv()`
```{r}
accel_data <- read_csv('data/accel_data.csv') %>% janitor::clean_names()
```
Use `pivot_longer()` to make the table tidy. Column `minute` would store the information of minute and `activity_count` would store the activity count for each minute of the day. I also add a column storing the information for weekend vs. weekday, that the weekends would be stored as TRUE while weekdays as FALSE. Then I convert `day` to factor so that it could be ordered from Monday to Sunday instead of in alphabetical order. Also `minute` is converted into numeric class.
```{r}
accel_data_tidy <- 
  accel_data %>%
  pivot_longer(starts_with('activity'),
               names_to = 'minute',
               names_prefix = 'activity_',
               values_to = 'activity_count') %>%
  mutate(weekend = ifelse(day %in% c('Saturday','Sunday'),TRUE,FALSE)) %>%
  mutate(day = factor(day,levels = c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'))) %>%
  mutate(minute = as.numeric(minute))
```
In total there are `r ncol(accel_data_tidy)` variables and `r nrow(accel_data_tidy)` observations.
Then, a table containing total activity count of each day is created. First use `group_by()` to select each single day by grouping both `week` and `day`, then use `summarise()` to add up all activity counts in one day. Lastly, use `pivot_wider()` to transfer the table into format that is more readable to human.
```{r}
accel_data_tidy %>%
  group_by(week,day) %>%
  summarise(total_activity_count = sum(activity_count)) %>%
  pivot_wider(names_from = day, values_from = total_activity_count) %>%
  knitr::kable(digit = 0)
```
There are some data points that is special in the table. Saturdays of week 4 and 5 only have 1440 counts (exact 1 for each minute all day) and that could be possibly caused by operation error. And the first day has far less counts comparing with other Mondays, that could possibly mean the man start wearing the accelerator half way of the day. So I would filtering those points off when doing the analysis by setting threshold total_activity_count > 100000.

Grouping by weekdays and weekends, we can see the average activity count of weekend is slightly less than weekday. 
```{r message=FALSE}
accel_data_tidy %>%
  group_by(week,day,weekend) %>%
  summarise(total_activity_count = sum(activity_count)) %>%
  filter(total_activity_count > 100000) %>%
  group_by(weekend) %>%
  summarise(mean_activity_count = mean(total_activity_count))
```
By plotting a box plot showing each day's distribution of total activity counts, the trend seems to be that the total activity count would reach the peak when Friday of each week.
```{r message=FALSE}
accel_data_tidy %>%
  group_by(week,day) %>%
  summarise(total_activity_count = sum(activity_count)) %>%
  filter(total_activity_count > 100000) %>%
  ggplot(aes(x = day,y = total_activity_count)) +
  geom_boxplot()
```

Use `ggplot()` to draw a plot showing the activity of each minute during a 24-day. The color of the plot represents the day of the week. Based on the graph, I can see there are several peaks over the day that indicates the individual tends to move more during those moment. Also, different days of the week might have different peak pattern (difference of peak in weekends). The first peak is around 400 minutes(possibly wake up and morning routine), 2nd peak is around noon (this peak is majorly for Sunday, and this might be the Sunday wake up time), 3rd and 4th peak is around 1000 and 1200. The activity at night(0-300) is less than the day time because of the sleep.
```{r}
accel_data_tidy %>%
  ggplot(aes(x = minute,y = activity_count, color = day)) +
  geom_point(aes(alpha = 0.5)) +
  labs(x = 'Time(minute)', y = 'Activity Count', title = 'Activity Count of the 24-hour Day')
```

### Problem3
Load ny_noaa data
```{r}
data("ny_noaa")
```


